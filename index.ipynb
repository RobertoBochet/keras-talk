{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intensive-border",
   "metadata": {},
   "source": [
    "<h1 class=\"intro_title\" style=\"text-align:center; font-size: 45px;\">Python course 2021</h1>\n",
    "<h2 class=\"intro_subtitle\" style=\"text-align:center; font-size: 30px;\">Introduction to machine learning<br/> with Keras</h2>\n",
    "\n",
    "<img class=\"intro_logo\" style=\"width:400px\" src=\"https://static.poul.org/assets/logo/logo_text_g.svg\" alt=\"POuL logo\"/>\n",
    "\n",
    "<p class=\"intro_author\" style=\"text-align: center; font-size: 18px;\">Roberto Bochet &lt;avrdudo@poul.org&gt;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-scholarship",
   "metadata": {},
   "source": [
    "# What is machine learning?\n",
    "##### (as basic as possible)\n",
    "<small style=\"font-size: 0.5em;\">Engineers, mathematicians and scientists have mercy of me!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.real(-0.5j*(math.e**(1j*x) - math.e**(-1j*x)) + \\\n",
    "              0.15*(math.e**(10j*x) + math.e**(-10j*x))) + \\\n",
    "              1e-4*np.e**x + np.random.normal(0,0.1,len(x))\n",
    "x = np.random.uniform(-5,5, 200)\n",
    "y = f(x) \n",
    "plt.title(\"What is this?\")\n",
    "plt.plot(x, y, \"o\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import signal\n",
    "x_fin = np.arange(-5, 5, 0.01)\n",
    "f_tri = lambda x: 2*np.abs(sp.signal.sawtooth(x - np.pi/2)) - 1\n",
    "plt.title(\"Is it a triangle wave?\")\n",
    "plt.plot(x, y.real, \"o\")\n",
    "plt.plot(x_fin, f_tri(x_fin), \"g\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sin = lambda x: np.sin(x)\n",
    "plt.title(\"...or is it a sine?\")\n",
    "plt.plot(x, y.real, \"o\")\n",
    "plt.plot(x_fin, f_sin(x_fin), \"r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_poly = lambda x: x - x**3/6 + x**5/120 - x**7/5040 + x**9/362880 - x**11/39916800\n",
    "plt.title(\"...maybe a polynomial?\")\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x_fin, f_poly(x_fin), \"m\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-delta",
   "metadata": {},
   "source": [
    "#### What are `triangle wave`, `sine` or `polynomial`?\n",
    "##### (Recap)\n",
    "\n",
    "We had some data in the form of tuple `(x,y)`\n",
    "\n",
    "We notice that there is a kind of relation between `x` and `y`, they are not random (mostly)\n",
    "\n",
    "So, we asked ourselves what value `y` assumes given a generic value of `x` (not presents in the orginal dataset)\n",
    "\n",
    "We answered with some mathematical functions which seems approximate the data quite well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-exclusion",
   "metadata": {},
   "source": [
    "#### So, from which among the suggested functions the dataset are generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-schedule",
   "metadata": {},
   "source": [
    "### Short answer: From nothing of them\n",
    "\n",
    "In a real scenario is unrealistic to completely identify the \"real process\" behind a dataset\n",
    "\n",
    "A **mathematical system can provides nothing more than an approximation of a real system**  \n",
    "and this is true for all the real system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-pipeline",
   "metadata": {},
   "source": [
    "### The mathematical functions  \n",
    "### we considered are called **mathematical models**\n",
    "an alternative to mathematical models could be the **physical models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445f649",
   "metadata": {},
   "source": [
    "So, a rasonable question we should answer could be  \n",
    "**\"Which mathematical model approximates better the behaviour of our real system?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec58a00",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    ">is the study of **computer algorithms** that  \n",
    "    improve **automatically** through **experience**  \n",
    "    and by the use of data.  \n",
    ">\n",
    ">    &#91;...&#93;  \n",
    ">\n",
    ">Machine learning algorithms build a model based  \n",
    "    on sample data, &#91;...&#93; in order to make **prediction**  \n",
    "    or **decisions** without being  \n",
    "    **explicitly programmed to do so**.  \n",
    ">\n",
    ">[from wikipedia](https://en.wikipedia.org/wiki/Machine_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a69c49",
   "metadata": {},
   "source": [
    "## ML branches\n",
    "\n",
    "ML splits itself in three macro areas\n",
    "\n",
    "*(incredible simplified summary)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869ca34",
   "metadata": {},
   "source": [
    "### Reinforced learning\n",
    "The model is trained like you would do with a pet:  \n",
    "it does a good job it is rewarded,  \n",
    "it does a mistake it is punished.\n",
    "\n",
    "The model should try to maximize the reward and avoid the punishes,  \n",
    "consequentially it would learn to do a good job without makes mistakes.\n",
    "\n",
    "Some applications:  \n",
    "[songs suggestion](https://medium.com/analytics-vidhya/emotion-based-music-recommendation-system-using-a-deep-reinforcement-learning-approach-6d23a24d3044),\n",
    "[autonomous drive](https://towardsdatascience.com/do-you-want-to-train-a-simplified-self-driving-car-with-reinforcement-learning-be1263622e9e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1d1f8",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "To the model is provided the input data and the result we would expect from it.\n",
    "\n",
    "The model should learn and generalize the relation between input and output,  \n",
    "so that given a never seen input it can be provided a reasonable output.\n",
    "\n",
    "Some applications:  \n",
    "[text translation](https://towardsdatascience.com/language-translation-with-rnns-d84d43b40571),\n",
    "[image classification](https://developers.google.com/machine-learning/practica/image-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e68f01",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "To the model are provided only the input data, without what we want aspect as output,  \n",
    "will be the model that will identify scheme and recurrences in the data.\n",
    "\n",
    "Some applications:  \n",
    "[paints style transfer](https://github.com/jcjohnson/neural-style),\n",
    "[words embedding](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988f050",
   "metadata": {},
   "source": [
    "It could be that for complex problems they are used together.\n",
    "\n",
    "#### However today we will talk olny about **supervised learning**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c25a52",
   "metadata": {},
   "source": [
    "# Feed-forward Neural Network\n",
    "is a really simple model inspired by the functioning of the brain\n",
    "\n",
    "## Let us see how to compose it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4539a85",
   "metadata": {},
   "source": [
    "### Neuron\n",
    "is the basic unit that composed the FNN\n",
    "![a neuron](./images/neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c472f4",
   "metadata": {},
   "source": [
    "Let us start with a really simple model, a linear combination of the input\n",
    "\n",
    "$ x = w_0 + w_1 u_1 + w_2 u_2 + \\dots + w_k u_k $\n",
    "\n",
    "*where $w_0$ is a parameter called bias, $u_i$ is the i-th input and $w_i$ is an arbitrary multiplication factor*\n",
    "\n",
    "So, the input data are linearly combined to get the value $x$ \n",
    "\n",
    "> The function could be seen (with $x=0$) as an equation  \n",
    "    defining a k-dimension [hyperplane](https://en.wikipedia.org/wiki/Hyperplane) of parameters $w_0, w_1, \\dots, w_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6b512",
   "metadata": {},
   "source": [
    "Then we can transform the value $x$ to get an output exploiting an arbitrary function\n",
    "\n",
    "$y = g(x)$\n",
    "\n",
    "Where $g(\\cdot)$ is called [**activation function**](https://en.wikipedia.org/wiki/Activation_function) (and it is generally non-linear one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as kr\n",
    "x_act = np.arange(-6,6,0.01)\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.suptitle(\"Some exmples of activatcion functions\")\n",
    "axs[0,0].set_title(\"Linear\")\n",
    "axs[0,0].plot(x_act, kr.activations.linear(x_act))\n",
    "axs[0,1].set_title(\"tanh\")\n",
    "axs[0,1].plot(x_act, kr.activations.tanh(x_act))\n",
    "axs[1,0].set_title(\"Sigmoid\")\n",
    "axs[1,0].plot(x_act, kr.activations.sigmoid(x_act))\n",
    "axs[1,1].set_title(\"ReLU\")\n",
    "axs[1,1].plot(x_act, kr.activations.relu(x_act));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159d840",
   "metadata": {},
   "source": [
    "$ x = w_0 + w_1 u_1 + w_2 u_2 + \\dots + w_k u_k $  \n",
    "$ y = g(x) $\n",
    "\n",
    "This couple of equations define entirely the concept of **Neuron** for the **FNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1997468",
   "metadata": {},
   "source": [
    "A single **neuron** defines the whole model of the simplest possible **FNN** at the base of the [**Perceptron**](https://en.wikipedia.org/wiki/Perceptron), a supervised algorithm invented in 1958 by [*Frank Rosenblatt*](https://en.wikipedia.org/wiki/Frank_Rosenblatt).\n",
    "\n",
    "It composed a binary classifier:  \n",
    "given an input it decided if this was part of a first class or a second one  \n",
    "(you are in or you are out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35292418",
   "metadata": {},
   "source": [
    "### Layer\n",
    "Anyway a lone Neuron is rather useless, so they are composed in structure called layer.\n",
    "An arbitrary number of neuron can be arranged side by side, in order to create a layer with $m$ output, where $m$ is the number of Neuron in the layer.\n",
    "\n",
    "This kind of layer is called **Dense layer** or **Fully-connected layer**\n",
    "\n",
    "![a single layer FNN](./images/layer.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b7297",
   "metadata": {},
   "source": [
    "Layers, in turn, can be stacked in order to improve the complexity of the final model.\n",
    "\n",
    "A single **Neuron** of a **Dense layer** has as inputs all the output of the previously layer  \n",
    "(from here the name **Fully-connected layer**) \n",
    "\n",
    "![a multi layers FNN](./images/multi_layers.svg)\n",
    "\n",
    "n.b. the propagation of signals go only from the input to the output, **there are not loops**!  \n",
    "From here the name **Feed-forward Neural Network**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9078b",
   "metadata": {},
   "source": [
    "A **FNN** model is defined by the **number of inputs**, the **number of layers**, the **number of neurons for layer** (each layer can have a difference number of them) and the **neurons' activation functions**, we called these parameters [**Hyperparameters**](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)).\n",
    "\n",
    "And by the values **$w_{i,j}$** which are called **weights**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3260712",
   "metadata": {},
   "source": [
    "Defined the **Hyperparameters** we defined a **FNN** working model, but it is a dummy!  \n",
    "##### An Hardware without a Software!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f2bbd7",
   "metadata": {},
   "source": [
    "## How to \"train\" a FNN?\n",
    "\n",
    "Up to now we only saw a **mathematical model**,  \n",
    "based on arranging an arbitrary number of **Neurons**,  \n",
    "but we still have no idea to how use the data to **teach** a **behavior** to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099f47e",
   "metadata": {},
   "source": [
    "The **FNN** training is treated as an optimization problem (as always...).\n",
    "\n",
    "So, after defined the **Hyperparameters** we should ask ourselves with values of the **weights** are the best possible ones in order to the **FNN** simulates the behavior of our \"real system\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be156e",
   "metadata": {},
   "source": [
    "#### [Optimization problem](https://en.wikipedia.org/wiki/Optimization_problem) (in a nutshell)\n",
    "\n",
    "Given a **mathematical model** (one or more parametric equations) and  \n",
    "a [**loss function (or cost function)**](https://en.wikipedia.org/wiki/Loss_function) (one to benchmark the model given a specific set of parameters)  \n",
    "we want find the parameters set that **minimize** (or **maximize**) it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4941d7",
   "metadata": {},
   "source": [
    "We already have a **mathematical model** (the **FNN** model)\n",
    "#### so we only need a **loss function**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a9ba2",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "In the literature several loss functions are proposed on the basis of the utility context for the **FNN**.\n",
    "\n",
    "**Mean Squared Error**, **Binary Crossentropy**, **Categorical Crossentropy** are some of the most used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac2fa9",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Unluckily (or not) **FNN** models overall are non-linear models,  \n",
    "so the choice of an algorithm to find the optimal **weights** is not a trivial decision.\n",
    "\n",
    "We could talk about them for hours, but (luckily for you) we have little time,  \n",
    "you need to know also this choice is important for the model result,  \n",
    "and that all the algorithms for training **FNN** are based on a magic stuff called [**Backpropagation**](https://en.wikipedia.org/wiki/Backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72989043",
   "metadata": {},
   "source": [
    "We can include in the **FNN** **Hyperparameters** also the **loss function** and the **optimization algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39a3c",
   "metadata": {},
   "source": [
    "Now we should have a general idea of how the **FNN**s work.\n",
    "\n",
    "...of course several concepts were omitted in the previous content,  \n",
    "we could talk for hours about **FNN**...  \n",
    "\n",
    "but now we have introduced all the arguments required to create our first model based on **FNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6dfda5",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "<img alt=\"keras logo\" src=\"./images/keras_logo.svg\" style=\"width:15%\"/>\n",
    "\n",
    "is an **open source** library thought to simplify the prototyping of [**deep neural networks**](https://en.wikipedia.org/wiki/Deep_learning).\n",
    "\n",
    "It provides an high level interface to back-end [**TensorFlow**](https://it.wikipedia.org/wiki/TensorFlow)  \n",
    "(previously some other back-ends were supported ðŸ˜•)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa603a1d",
   "metadata": {},
   "source": [
    "**n.b.**  \n",
    "a develop directly on **TensorFlow** with **Python** is possible,  \n",
    "but **Keras** provides an high abstraction level drastically speed up and simplify the prototyping with **deep neural networks**.\n",
    "\n",
    "**Keras** was considered so important that now it is shipped also in the **TensorFlow** libraries (`tensorflow.keras`) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0647fb",
   "metadata": {},
   "source": [
    "#### Let us start with Keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dfd7f",
   "metadata": {},
   "source": [
    "# Our first FNN\n",
    "\n",
    "As first experiment we resume the first dataset we saw at the start of this talk  \n",
    "and let us try to build and train a FNN on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a4ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Our dataset\")\n",
    "plt.plot(x, y, \"o\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958f459",
   "metadata": {},
   "source": [
    "In particular we are looking for a model that characterizes the relation between `x` and `y` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1935fb0d",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Let us start defining a simple **FNN** model,  \n",
    "also called \"choose the **Hyperparameters**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f879e",
   "metadata": {},
   "source": [
    "In this simple model we will use a 3-layers **FNN** with a single input (`x`).\n",
    "\n",
    "Firsts two layers will have some **Neurons** with a [**Sigmoid**](https://en.wikipedia.org/wiki/Sigmoid_function) as **activation function**.\n",
    "\n",
    "The last one (output layer) instead will have only one **Neuron** with a **Linear** activation function,  \n",
    "because we need a single continuous value (`y`) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the keras module\n",
    "import tensorflow.keras as kr\n",
    "\n",
    "# create a new empty model\n",
    "model = kr.Sequential()\n",
    "\n",
    "# set the input size\n",
    "model.add(kr.layers.InputLayer(input_shape=(1,)))\n",
    "# add the three Dense layers to the model\n",
    "model.add(kr.layers.Dense(30, activation=kr.activations.sigmoid))\n",
    "model.add(kr.layers.Dense(10, activation=kr.activations.sigmoid))\n",
    "model.add(kr.layers.Dense(1, activation=kr.activations.linear))\n",
    "\n",
    "# print a summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237556d8",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Missing **Hyperparameters** are the **optimization algorithm** and **loss function**,&nbsp;  \n",
    "for the first we will use the [**Adam**](https://keras.io/api/optimizers/adam/) algorithm  \n",
    "and since we want to do a [nonlinear regression](https://en.wikipedia.org/wiki/Nonlinear_regression) we can use the [**Mean Squared Error**](https://en.wikipedia.org/wiki/Mean_squared_error) as loss function \n",
    "\n",
    "We will use this choices to configure the FNN for the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete the FNN setup with optimizer algorithm and loss function \n",
    "model.compile(\n",
    "    optimizer=kr.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=kr.losses.mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75149ff4",
   "metadata": {},
   "source": [
    "##### The **FNN** is ready to be trained!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c35ed7",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will use the method `fit` to start the model training.  \n",
    "We have to give to it the inputs data, the expected output data,  \n",
    "and the times the training algorithm will have to iterate on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdbe05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x, y, epochs=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a73da",
   "metadata": {},
   "source": [
    "#### The training is over!\n",
    "Let us check how it went!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(history.history[\"loss\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d1bd2",
   "metadata": {},
   "source": [
    "From our trained model we are now able to get an estimation on the relation between `x` and `y` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75263b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.arange(-5, 5, 0.01)\n",
    "y_pred = model.predict(x_pred)\n",
    "\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(x_pred, y_pred, \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb19e78",
   "metadata": {},
   "source": [
    "We got a model(extremely limited) of our real system that we can reuse in order to do predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a47f38",
   "metadata": {},
   "source": [
    "# The \"Hello world\" of ML\n",
    "\n",
    "So, we saw a first(useless) model realized on garbage data, it is the time to realize our first model on a real challenge\n",
    "\n",
    "In the machine learning amateur world there is a famous site to challenge you with several ML problems.  \n",
    "It is [Kaggle](https://www.kaggle.com) and it proposes a first challenge to begin with this world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31755bf2",
   "metadata": {},
   "source": [
    "Before to start we need to authenticate to **Kaggle**,&nbsp;  \n",
    "to do this we need to require a token API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c962be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert here your authentication data\n",
    "%env KAGGLE_USERNAME={YOUR_USERNAME}\n",
    "%env KAGGLE_KEY={YOUR_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5309f3",
   "metadata": {},
   "source": [
    "# The Titanic challenge\n",
    "\n",
    "It will be given to us two **lists of Titanic passengers** with some informations,  \n",
    "the first one (**training dataset**) with an indication **if the passenger survived**,&nbsp;  \n",
    "the second one (**test dataset**) without the passenger survived informations.\n",
    "\n",
    "Using the training dataset we have to build a model in order to **predict** which passengers in the test dataset survived.\n",
    "\n",
    "## ðŸ¥³ only positive vibes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a570df",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "First, let us retrieve the dataset, to do this we will exploit the [**Kaggle API**](https://github.com/Kaggle/kaggle-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# this is a special cell, the above code is pass to bash (directly to the os)\n",
    "kaggle competitions download -c titanic # download the compressed datasets\n",
    "unzip -o titanic.zip -d titanic # unzip the datasets in `titanic` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cedb09",
   "metadata": {},
   "source": [
    "Now we have to load the dataset in Python, we can choose several way to do it.\n",
    "\n",
    "A powerful library thought to work with complex dataset could be [**Pandas**](https://pandas.pydata.org/), I think you  will be fine with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70618e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv(\"./titanic/train.csv\") # load the training dataset\n",
    "ds # this syntax force jupyter to render the dataset as a table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9b67d",
   "metadata": {},
   "source": [
    "This dataset are really heterogeneous, this present data on the shape of `string`, `integer`, `float` and also `enum`.\n",
    "\n",
    "So, we have to pre-process the data before use it to train our model  \n",
    "##### The data pre-processing is not an optional step in ML\n",
    "##### It could be the critical point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5704606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless(maybe) columns\n",
    "ds.drop(columns=[\"Embarked\", \"Cabin\", \"SibSp\", \"Parch\", \"Ticket\", \"PassengerId\"], inplace=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899c1ca",
   "metadata": {},
   "source": [
    "Well, now we have less data to work with, let us look to the `Age` data.\n",
    "\n",
    "The age data is **not available for all** the dataset entries, so we have to solve this issue.\n",
    "\n",
    "We have two options (IMO), set it to an **arbitrary or random value** for the missing ones,  \n",
    "or another way could be to **calculate the average age** from the other passengers and use it as **estimation** for the missing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_average = ds[\"Age\"].mean(skipna=True) # compute average age from only not NaN values\n",
    "age_average = np.around(age_average, decimals=2) # preserve only two decimals\n",
    "print(f\"The estimated average age is {age_average}\")\n",
    "\n",
    "ds.loc[ds[\"Age\"].isna(), \"Age\"] = age_average # override NaN ages with the average age\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07ba5d",
   "metadata": {},
   "source": [
    "`Sex` and `Name` are `string` we cannot use it directly!\n",
    "\n",
    "The first will be converted to `integer`.\n",
    "\n",
    "From the `Name` we can identify the title (e.g. `Mrs.`, `Miss.`, ecc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3aa7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# enumerate sex\n",
    "ds.loc[ds[\"Sex\"] == \"female\", \"Sex\"] = 0\n",
    "ds.loc[ds[\"Sex\"] == \"male\", \"Sex\"] = 1\n",
    "\n",
    "# enumerate title\n",
    "ds.loc[:,\"Title\"] = 0 # set default value for title to 0\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Rev.\"), \"Title\"] = 1\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Miss.\"), \"Title\"] = 2\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Mr.\"), \"Title\"] = 3\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Mrs.\"), \"Title\"] = 4\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Master.\"), \"Title\"] = 5\n",
    "ds.loc[ds[\"Name\"].str.contains(\"Dr.\"), \"Title\"] = 6\n",
    "ds.drop(columns=\"Name\", inplace=True) # delete the `Name` column, it is not longer userful\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2364ce",
   "metadata": {},
   "source": [
    "We have define arbitrary values for the titles, but there is not an intrinsic hierarchical titles order (`Miss` < `Mrs.`?),  \n",
    "whatever we erroneously introduced it.\n",
    "\n",
    "[**One-hot encoding**](https://it.wikipedia.org/wiki/One-hot) is common system to solve this issue, for each category a binary codification with a single `1` is created, let us see it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bf107",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_onehot = pd.get_dummies(ds[\"Title\"], prefix=\"Title\") # create one-hot encode based on `Title`\n",
    "\n",
    "ds = pd.concat([ds, title_onehot], axis=1) # merge the one-hot table to original dataset\n",
    "\n",
    "ds.drop(columns=\"Title\", inplace=True) # drop the not longer required `Title` column\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87c681",
   "metadata": {},
   "source": [
    "The dataset is almost ready, so we have to do some final operations.\n",
    "\n",
    "Let us separate inputs and desired output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds.drop(columns=\"Survived\").to_numpy(dtype=np.float16) # our inputs\n",
    "y = ds[\"Survived\"].to_numpy() # our desired output\n",
    "x.shape, y.shape # let us check the shape of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0219a",
   "metadata": {},
   "source": [
    "### Wait a moment!\n",
    "### Are we sure we can behave like in the regression problem?\n",
    "# ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ba10d",
   "metadata": {},
   "source": [
    "In the first problem we saw simple data and we immediately realized that there was some kind of mathematical relation between $x$ and $y$... maybe a little noise, but the relation was obvious.\n",
    "\n",
    "In this case we can say the some thing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a6086c",
   "metadata": {},
   "source": [
    "Also in the noise, if we search well enough we will able to find some kind of pattern we can memorize, but this cannot help us to improve our model, indeed these \"conclusions\" can be deceptive our **FNN**.\n",
    "\n",
    "This is a well known problem of any kind of model identification system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4cc71",
   "metadata": {},
   "source": [
    "## [Overfitting](https://en.wikipedia.org/wiki/Overfitting)\n",
    "\n",
    "When it occurs, our model stops to learn useful pattern and starts to memorize the training dataset.\n",
    "\n",
    "This kind of mechanize is not simple to avoid, because if during the training we look only to **loss** value we  will see it tends to zero,  \n",
    "so we can erroneously think that our model is improving, while it is losing generality!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6143d01",
   "metadata": {},
   "source": [
    "#### So, how can we detect overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0cdd5",
   "metadata": {},
   "source": [
    "### [**cross validation**](https://en.wikipedia.org/wiki/Cross-validation_(statistics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1dd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import sklearn.model_selection\n",
    "train_x, val_x, train_y, val_y = skl.model_selection.train_test_split(x, y,\n",
    "                                                                      train_size=0.7,\n",
    "                                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-milton",
   "metadata": {},
   "source": [
    "<h1 class=\"outro_title\" style=\"text-align:center; font-size: 35px;\">Thank you!</h1>\n",
    "\n",
    "<img class=\"outro_logo\" style=\"width: 20%;\" src=\"https://static.poul.org/assets/logo/logo_g.svg\" alt=\"POuL logo\">\n",
    "\n",
    "<a class=\"outro_license\" style=\"display: block; margin: 20px auto;\" rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a>\n",
    "<p class=\"outro_license_text\" style=\"font-size: 15px; text-align: center;\">Licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International<br/>\n",
    "    Notebook source code available in <a href=\"https://gitlab.poul.org/corsi/Python/keras/-/tree/2021\">this repo</a></p>\n",
    "\n",
    "<p class=\"outro_author\" style=\"text-align: center; font-size: 18px;\">Roberto Bochet &lt;avrdudo@poul.org&gt;</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
